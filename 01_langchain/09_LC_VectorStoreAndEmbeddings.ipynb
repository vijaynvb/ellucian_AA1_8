{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "dQj_xgvpT9uy",
      "metadata": {
        "id": "dQj_xgvpT9uy"
      },
      "source": [
        "# **VectorStore and Embeddings**\n",
        "\n",
        "We need vector stores and embeddings to efficiently handle and retrieve relevant information from large text datasets. Embeddings convert text data into numerical vectors that capture semantic meaning, enabling more accurate search and retrieval by understanding context and similarity. Vector stores index these embeddings, allowing for quick and scalable similarity searches, essential for applications like recommendation systems, information retrieval, and natural language processing tasks. Combining both ensures high performance in accessing and utilizing vast amounts of text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c81a13b1",
      "metadata": {
        "id": "c81a13b1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "%pip install --upgrade langchain_classic langchain_community langchain_aws pypdf tiktoken faiss-cpu\n",
        "%pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "uhrSlEaBzNoZ",
      "metadata": {
        "id": "uhrSlEaBzNoZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = os.getenv(\"AWS_DEFAULT_REGION\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IirOq9leTbm5",
      "metadata": {
        "id": "IirOq9leTbm5"
      },
      "source": [
        "We just discussed `Document Loading` and `Splitting`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ce244283",
      "metadata": {
        "id": "ce244283"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
            "Ignoring wrong pointing object 6 0 (offset 0)\n",
            "Ignoring wrong pointing object 9 0 (offset 0)\n",
            "Ignoring wrong pointing object 12 0 (offset 0)\n",
            "Ignoring wrong pointing object 23 0 (offset 0)\n"
          ]
        }
      ],
      "source": [
        "from langchain_classic.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"./content/Vijay Trainer Profile_Sep_25.pdf\")\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f52d2eec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f52d2eec",
        "outputId": "16d7480c-fbc6-4c38-82b3-ec565997c501"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split\n",
        "from langchain_classic.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xUR4SEbtTloz",
      "metadata": {
        "id": "xUR4SEbtTloz"
      },
      "source": [
        "# **Embeddings**\n",
        "\n",
        "Embedding is a technique that transforms text or other data into numerical vectors, capturing semantic relationships and contextual meaning. These vectors enable machines to process and analyze the data more effectively, facilitating tasks such as search, recommendation, and natural language understanding.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "Let's take our splits and embed them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "87dac68a",
      "metadata": {
        "id": "87dac68a"
      },
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "\n",
        "from langchain_aws import BedrockEmbeddings\n",
        "\n",
        "embedding = BedrockEmbeddings(\n",
        "    model_id=\"amazon.titan-embed-text-v2:0\"\n",
        ")\n",
        "\n",
        "sentence1 = \"i like Workplace conditions\"\n",
        "sentence2 = \"i like Employees  Efficiency and Effectiveness\"\n",
        "sentence3 = \" Employee’s Characteristics and Creativity\"\n",
        "\n",
        "embedding1 = embedding.embed_query(sentence1)\n",
        "embedding2 = embedding.embed_query(sentence2)\n",
        "embedding3 = embedding.embed_query(sentence3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f3875c82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3875c82",
        "outputId": "a24a17ac-f809-4258-a6ba-d2d9bca757c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(1.0000000989210367)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.dot(embedding2, embedding2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yzgjhoeSTr9T",
      "metadata": {
        "id": "yzgjhoeSTr9T"
      },
      "source": [
        "# **Vectorstores**\n",
        "\n",
        "A vector store is a database designed to store and manage numerical vectors, such as embeddings, for efficient retrieval and similarity search. It enables quick and accurate matching of vectors, facilitating tasks like nearest neighbor search, clustering, and recommendation systems based on vector similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6a979239",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a979239",
        "outputId": "be1c8d06-675d-492f-eae9-a3aedb5f52d1"
      },
      "outputs": [],
      "source": [
        "from langchain_classic.vectorstores import FAISS\n",
        "persist_directory = 'docs/faiss/'\n",
        "# !rm -rf ./docs/faiss  # remove old database files if any\n",
        "\n",
        "vectordb = FAISS.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2hpDRTy06N2o",
      "metadata": {
        "id": "2hpDRTy06N2o"
      },
      "outputs": [],
      "source": [
        "question = \"What is name of the trainer?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "HPx0V_iQ6SCC",
      "metadata": {
        "id": "HPx0V_iQ6SCC"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5cc7a742",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "qSIyTmv96XYS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "qSIyTmv96XYS",
        "outputId": "27db4309-c433-4322-8bf8-e64b1613a0c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Trainer Details   Vijaya Bhaskar Reddy N         Email: vijay@swayaan.com Phone Number: +919845733399   Summary  Total Experience: 19 Years || Training Delivery: 10+ Years || Total Trainings: 500+ Highly motivated technology trainer with 19+ years of experience in training small and large groups across diverse industries primarily on DevOps, Azure, AWS, GCP, APIs, Micro services, SOA, Python, Testing, Snowflake, Performance Testing, Jmeter, Cucumber & Cloud Computing. Proven success in leveraging educational theories and methodologies to design, develop, and deliver successful training programs and integrate instructional technology to provide onsite and virtual training. Efficient trainings delivered with real life use cases and scenarios  Expertise   • GAI, Prompt Engineering, Deep Learning, ML, AI, LLM’s, SLM, MLOps, LLMOps, Responsible AI.  • Agentic AI: Langchain, LangGraph, Lang Smith, [Eval], Arize.AI, RAGA’s,  AWS Bedrock, Agents, AWS Sagemaker, Azure AI Foundry, Semantic Kernel SDK, AzureML. • Code Assistant AI: Github Copilot [Certified], Tabnine, Amazon Q AWS Whisper, coursor_ai, windsurf_ai. • AI Tools: Microsoft Office Copilot, OpenAI ChatGPT, Google Gemini, Gamma,  • NLP, TensorFlow, Image Processing, Speech Processing, Nuance SDK. • Azure Cloud Platform, Amazon Web Services, Google Cloud Platform. • Dot.Net Core, Entity framework Core, Micro Services Development • Micro Services with Kubernetes, Docker, Helm, Istio • DevOps tools - Terraform, Codefresh,'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "o-UzxXZw7l1h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-UzxXZw7l1h",
        "outputId": "fb10ebb8-402a-4185-d5d4-21382d074dd9"
      },
      "outputs": [],
      "source": [
        "# Let's save this so we can use it later!\n",
        "vectordb.save_local(persist_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "59a8a31f",
      "metadata": {},
      "outputs": [],
      "source": [
        "vectordb2 = FAISS.load_local(\n",
        "    persist_directory,\n",
        "    embedding,\n",
        "    allow_dangerous_deserialization=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9bbf55ba",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vectordb2.docstore._dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "48d366df",
      "metadata": {},
      "outputs": [],
      "source": [
        "docs1 = vectordb2.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d87dc4c1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2e8a5858",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Trainer Details   Vijaya Bhaskar Reddy N         Email: vijay@swayaan.com Phone Number: +919845733399   Summary  Total Experience: 19 Years || Training Delivery: 10+ Years || Total Trainings: 500+ Highly motivated technology trainer with 19+ years of experience in training small and large groups across diverse industries primarily on DevOps, Azure, AWS, GCP, APIs, Micro services, SOA, Python, Testing, Snowflake, Performance Testing, Jmeter, Cucumber & Cloud Computing. Proven success in leveraging educational theories and methodologies to design, develop, and deliver successful training programs and integrate instructional technology to provide onsite and virtual training. Efficient trainings delivered with real life use cases and scenarios  Expertise   • GAI, Prompt Engineering, Deep Learning, ML, AI, LLM’s, SLM, MLOps, LLMOps, Responsible AI.  • Agentic AI: Langchain, LangGraph, Lang Smith, [Eval], Arize.AI, RAGA’s,  AWS Bedrock, Agents, AWS Sagemaker, Azure AI Foundry, Semantic Kernel SDK, AzureML. • Code Assistant AI: Github Copilot [Certified], Tabnine, Amazon Q AWS Whisper, coursor_ai, windsurf_ai. • AI Tools: Microsoft Office Copilot, OpenAI ChatGPT, Google Gemini, Gamma,  • NLP, TensorFlow, Image Processing, Speech Processing, Nuance SDK. • Azure Cloud Platform, Amazon Web Services, Google Cloud Platform. • Dot.Net Core, Entity framework Core, Micro Services Development • Micro Services with Kubernetes, Docker, Helm, Istio • DevOps tools - Terraform, Codefresh,'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs1[0].page_content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92J_MgV-S0BQ",
      "metadata": {
        "id": "92J_MgV-S0BQ"
      },
      "source": [
        "# Failure modes\n",
        "\n",
        "This seems great, and basic similarity search will get you 80% of the way there very easily.\n",
        "\n",
        "But there are some failure modes that can creep up.\n",
        "\n",
        "Here are some edge cases that can arise - we'll fix them in the next class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F4kwHuw87uja",
      "metadata": {
        "id": "F4kwHuw87uja"
      },
      "outputs": [],
      "source": [
        "question = \"what is the trainer email id?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7qW3nwG72U5",
      "metadata": {
        "id": "d7qW3nwG72U5"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(question,k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "esPJir0ZTGCG",
      "metadata": {
        "id": "esPJir0ZTGCG"
      },
      "source": [
        "Notice that we're getting duplicate chunks.\n",
        "\n",
        "Semantic search fetches all similar documents, but does not enforce diversity.\n",
        "\n",
        "docs[0] and docs[1] are identical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SVQInNyGS-mn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVQInNyGS-mn",
        "outputId": "1e8f7f7c-93c0-4736-c8a9-9d6be2e9374a"
      },
      "outputs": [],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nwUldKazTBI6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwUldKazTBI6",
        "outputId": "4d5dbe51-2644-45d8-f695-8ef986fa42c3"
      },
      "outputs": [],
      "source": [
        "docs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z9lGpbaBTM5A",
      "metadata": {
        "id": "z9lGpbaBTM5A"
      },
      "source": [
        "We can see a new failure mode."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba1fa29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ba1fa29",
        "outputId": "e6f90e17-3cf9-4988-f3a3-615a88042e35"
      },
      "outputs": [],
      "source": [
        "question = \"What is the experience of the trainer?\"\n",
        "docs = vectordb.similarity_search(question,k=5)\n",
        "for doc in docs:\n",
        "    print(doc.metadata)\n",
        "print(docs[4].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ua5k5b2oWe-o",
      "metadata": {
        "id": "ua5k5b2oWe-o"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "## **Objective**\n",
        "\n",
        "In this activity, you will learn to use embeddings and vector stores to perform efficient similarity searches and data retrieval. You will practice creating embeddings from text data, storing them in a vector store, and retrieving relevant information based on similarity queries.\n",
        "\n",
        "## **Scenario**\n",
        "\n",
        "You are building a recommendation system that suggests documents based on user queries. To achieve this, you will use LangChain to create embeddings from text data and store these embeddings in a vector store. You will then use the vector store to find the most relevant documents for a given query.\n",
        "\n",
        "## **Steps**\n",
        "\n",
        "* Load and Split Documents\n",
        "* Create Embeddings\n",
        "* Store Embeddings in Vector Store\n",
        "* Perform Similarity Search"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
